{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Large Datasets\n",
    "\n",
    "As the size of data get larger more and more problems will occur in our workflow. Either the it will take too much **time**, will not fit into the **memory** of our computer or it will be harder to **comprehend**. \n",
    "\n",
    "The same is true for **visualization**: plotting will take more time and the figure will not be able to tell us the necessary information or might be even misleading the same techniques.\n",
    "\n",
    "In the following notebooks we will address some of these issues following some articles and tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce data size if possible\n",
    "\n",
    "See the [02-Pandas-reduce-data-size](02-Pandas-reduce-data-size.ipynb) notebook!\n",
    "\n",
    "* Store data in the right format\n",
    "* lose some of the data in order to increase the efficiency of your code\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation and packages\n",
    "\n",
    "https://laptrinhx.com/scaling-pandas-comparing-dask-ray-modin-vaex-and-rapids-1172788594/\n",
    "\n",
    "Funny site: https://anvaka.github.io/vs/?query=dask\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1024/0*P7Xv__4reO9WuF2I.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas together with Dask\n",
    "\n",
    "* sample of the data\n",
    "\n",
    "https://www.machinelearningplus.com/python/dask-tutorial/:\n",
    "\n",
    "You may use Spark or Hadoop to solve this. But, these are not python environments. This stops you from using numpy, sklearn, pandas, tensorflow, and all the commonly used Python libraries for ML.\n",
    "\n",
    "* Dask tutorial\n",
    "https://medium.com/@gongster/dask-an-introduction-and-tutorial-b42f901bcff5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "follow https://towardsdatascience.com/how-to-handle-large-datasets-in-python-with-pandas-and-dask-34f43a897d55follow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "\n",
    "The underlying problem is that we cannot distinguish between the datapoints because\n",
    "* **the figure is too crowded**\n",
    "* **when using alpha values -> over- or undersaturation**\n",
    "* **saturation cannot be overcome by binning (heatmap)**\n",
    "\n",
    "or the plotting interface is **too slow** to respond **to any interaction**\n",
    "\n",
    "A good introduction:\n",
    "* https://www.slideshare.net/continuumio/visualizing-billions-of-data-points-doing-it-right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datashader\n",
    "<img src=\"https://github.com/holoviz/datashader/raw/master/doc/_static/logo_stacked.png\" width=300>\n",
    "\n",
    "With the [holoviews](holoviews.org/) suite interactive exploration of large datasets are possibble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datashading pipeline:\n",
    "1. Select data and project it (e.g. scatter plot)\n",
    "2. Aggregate points into fixed set of bins --> result in one or more scalars\n",
    "3. Transform data using transfer functions --> yields a visible image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T11:40:36.422116Z",
     "start_time": "2020-12-07T11:40:36.290828Z"
    }
   },
   "source": [
    "Example notebooks from the [datashader repository](https://github.com/holoviz/datashader):\n",
    "* **How to Visualize a large dataset**: Datashader-01-Pipeline.ipynb\n",
    "* **Aspects and concepts**: Datashader-02-Interactivity.ipynb\n",
    "* **Networks**: Datashader-03-Networks.ipynb       \n",
    "* **Timeseries example**: Datashader-04-Timeseries.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
